#!/usr/bin/env python3
"""
AI History Tattoo Generator - Main Script
This script orchestrates the entire workflow from browsing history to tattoo images.
"""

import json
import os
import requests
import time
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv

# Import Google AI libraries
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âš ï¸  Google AI library not installed. Install with: pip install google-genai")
    genai = None
    types = None

# Load environment variables from .env file
load_dotenv()

class TattooGenerator:
    def __init__(self):
        self.history_file = "history_summary.json"
        self.prompts_file = "generated_prompts.json"
        self.ollama_url = "http://localhost:11434"
        self.model_name = "gemma2:2b"
        self.google_api_token = os.getenv("GOOGLE_API_TOKEN")
        
    def check_ollama_connection(self):
        """Check if Ollama is running and get available models"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                print(f"âœ… Ollama connection successful! Found {len(models)} models")
                model_names = [model["name"] for model in models]
                print(f"Available models: {', '.join(model_names)}")
                return True
            else:
                print(f"âŒ Ollama connection failed: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ Ollama connection failed: {e}")
            print("Make sure Ollama is running: ollama serve")
            return False

    def generate_with_ollama(self, prompt):
        """Generate response using Ollama"""
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.9,
                        "top_p": 0.9
                    }
                }
            )
            
            if response.status_code == 200:
                return response.json()["response"]
            else:
                print(f"âŒ Generation failed: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ Generation error: {e}")
            return None

    def generate_image_with_google(self, prompt):
        """Generate image using Gemini 2.0 Flash image generation"""
        if not self.google_api_token:
            print("âŒ GOOGLE_API_TOKEN not set. Skipping Gemini image generation.")
            return None
        
        if not genai:
            print("âŒ Google AI library not available. Skipping Gemini image generation.")
            return None
        
        try:
            print(f"ğŸ¨ Generating image with Gemini 2.0 Flash: {prompt[:50]}...")
            
            # Use the new Gemini 2.0 Flash image generation code
            client = genai.Client(api_key=self.google_api_token)
            
            contents = [prompt]
            
            response = client.models.generate_content(
                model="gemini-2.0-flash-preview-image-generation",
                contents=contents,
                config=types.GenerateContentConfig(
                  response_modalities=['TEXT', 'IMAGE']
                )
            )
            
            for part in response.candidates[0].content.parts:
                if part.text is not None:
                    print(part.text)
                elif part.inline_data is not None:
                    image = Image.open(BytesIO((part.inline_data.data)))
                    # Convert PIL image to bytes for saving
                    img_byte_arr = BytesIO()
                    image.save(img_byte_arr, format='PNG')
                    img_byte_arr = img_byte_arr.getvalue()
                    return img_byte_arr
            
            print("âŒ No images generated by Gemini")
            return None
                
        except Exception as err:
            print(f"âŒ Gemini image generation error: {err}")
            return None

    def load_history_summary(self):
        """Load browsing history summary"""
        print("ğŸ“š Loading browsing history...")
        try:
            with open("history_summary.json", "r", encoding="utf-8") as f:
                summary = json.load(f)
            print(f"âœ… Loaded history with {len(summary.get('top_domains_with_titles', []))} top domains")
            return summary
        except FileNotFoundError:
            print("âŒ history_summary.json not found. Please run summarize_history.py first.")
            return None
        except Exception as e:
            print(f"âŒ Error loading history: {e}")
            return None

    def generate_single_image(self, prompt, index):
        """Generate a single image for the given prompt"""
        print(f"ğŸ¨ Generating image with Gemini 2.0 Flash: {prompt[:50]}...")
        
        try:
            # Try Gemini 2.0 Flash
            if self.google_api_token:
                image_data = self.generate_image_with_google(prompt)
                if image_data:
                    timestamp = int(time.time())
                    filename = f"tattoo_gemini_{timestamp}.png"
                    with open(filename, "wb") as f:
                        f.write(image_data)
                    print(f"âœ… Image saved as: {filename}")
                    return True
                else:
                    print("âŒ Failed to generate AI image - no placeholder created")
                    return False
            else:
                print("âŒ No Google API token available - no placeholder created")
                return False
            
        except Exception as e:
            print(f"âŒ Error generating image: {e}")
            return False

    def save_prompts(self, response, image_prompts, summary):
        """Save prompts to JSON file"""
        prompts_data = {
            "image_prompts": image_prompts,
            "summary": summary,
            "timestamp": time.time()
        }
        
        with open(self.prompts_file, "w", encoding="utf-8") as f:
            json.dump(prompts_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Saved prompts to '{self.prompts_file}'")

    def generate_tattoo_prompts(self, summary):
        """Generate tattoo design prompts using Ollama with rich domain context"""
        top_domains_data = summary.get('top_domains_with_titles', [])
        
        if not top_domains_data:
            print("âŒ No domain data found in summary")
            return None
        
        # Create rich context string from domain data
        context_parts = []
        for domain_data in top_domains_data[:15]:  # Use top 15 domains
            domain = domain_data['domain']
            visit_count = domain_data['visit_count']
            titles = domain_data['top_titles'][:3]  # Use top 3 titles per domain
            
            context_parts.append(f"Domain: {domain} ({visit_count} visits)")
            for i, title in enumerate(titles, 1):
                # Clean title by removing common web artifacts
                clean_title = title.replace('https', '').replace('www', '').replace('com', '')
                clean_title = ' '.join([word for word in clean_title.split() if len(word) > 2])
                context_parts.append(f"  {i}. {clean_title}")
            context_parts.append("")  # Empty line for readability
        
        context_string = "\n".join(context_parts)
        
        prompt = f"""
        You are a world-class tattoo artist and AI prompt engineer who specializes in designing ultra-detailed tattoo prompts for Gemini Image API.

        Input: The userâ€™s browsing history grouped by domains and their most visited pages:

        {context_string}

        Your task:
        1. Analyze the browsing history to understand the userâ€™s lifestyle, interests, passions, favorite brands, hobbies, or frequently visited platforms.
        2. Extract exactly 5 unique, meaningful keywords or entities that best represent the user (e.g. â€œAir Jordan 1 sneakersâ€, â€œBitcoin tradingâ€, â€œMarvel comicsâ€, â€œTwitch streamingâ€, â€œColdplay concertsâ€).
        - Do NOT use generic terms like â€œgoogle, shopping, sneakers, investmentâ€.
        - Instead use specific phrases (e.g. â€œNike Air Jordan 1 Retro Highâ€, â€œAmazon Kindle booksâ€, â€œYouTube travel vlogsâ€).
        3. Generate 5 unique tattoo design prompts, one per keyword.
        - Each prompt should:
            - Be under 480 tokens (ideal: 300â€“400 chars).
            - Describe the **main subject** clearly (the tattooâ€™s core symbol).
            - Add **context + storytelling** (where it comes from, what it represents).
            - Include **tattoo-specific style details** (black & grey realism, fine-line minimalism, neo-traditional, watercolor, geometric, cyberpunk, etc.).
            - Add **visual details** (colors, shading, textures, lighting).
            - Make the design **cool, artistic, and ultra-realistic**.

        Format output like this:

        **Keywords:** [keyword1], [keyword2], [keyword3], [keyword4], [keyword5]

        **Prompt 1:** [Ultra-detailed tattoo prompt based on keyword1]  
        **Prompt 2:** [Ultra-detailed tattoo prompt based on keyword2]  
        **Prompt 3:** [Ultra-detailed tattoo prompt based on keyword3]  
        **Prompt 4:** [Ultra-detailed tattoo prompt based on keyword4]  
        **Prompt 5:** [Ultra-detailed tattoo prompt based on keyword5]
        """

        print("ğŸ¨ Generating tattoo ideas...")
        print("=" * 50)
        print("ğŸ¨ GENERATED TATTOO PROMPTS")
        print("=" * 50)
        
        print(prompt,"prompt for ollama +++++++++++++++++++")
        response = self.generate_with_ollama(prompt)
        
        print(response, "Response from ollama---------")
        print("=" * 50)
        
        return response

    def extract_direct_prompts(self, response, summary=None):
        """Extract keywords and direct prompts from Ollama's response"""
        lines = response.split('\n')
        image_prompts = []
        current_prompt = ""
        in_prompt = False
        
        # Extract prompts from the response
        for line in lines:
            line = line.strip()
            
            # Handle **Prompt X:** format (with markdown)
            if line.startswith("**Prompt") and ":**" in line:
                # Start of a new prompt
                in_prompt = True
                # Extract the prompt after the colon
                prompt_part = line.split(":**", 1)[1].strip()
                if prompt_part:
                    # Remove asterisks and quotes
                    prompt_part = prompt_part.replace("*", "").strip('"').strip("'").strip()
                    if prompt_part:
                        current_prompt = prompt_part
                continue
            
            # If we're in a prompt and the line starts with asterisk, it's part of the prompt
            elif in_prompt and line.startswith("*") and not line.startswith("**Style:"):
                # This is part of the prompt description
                prompt_part = line.replace("*", "").strip()
                if prompt_part:
                    current_prompt += " " + prompt_part
                continue
            
            # If we hit a style line, end the current prompt
            elif line.startswith("*Style:") or line.startswith("**Style:"):
                if current_prompt:
                    image_prompts.append(current_prompt.strip())
                    current_prompt = ""
                    in_prompt = False
                continue
            
            # If we hit an empty line or different format, end the current prompt
            elif in_prompt and (not line or line.startswith("**") or line.startswith("Prompt")):
                if current_prompt:
                    image_prompts.append(current_prompt.strip())
                    current_prompt = ""
                    in_prompt = False
                continue
            
            # Handle "Prompt: " format
            elif line.startswith("Prompt: "):
                prompt = line.replace("Prompt: ", "").strip()
                if prompt and not prompt.startswith("**") and not prompt.startswith("*"):
                    image_prompts.append(prompt)
            
            # Handle numbered prompts like "1. [prompt]"
            elif any(line.startswith(f"{i}.") for i in range(1, 10)):
                parts = line.split(".", 1)
                if len(parts) > 1:
                    prompt = parts[1].strip()
                    if prompt and not prompt.startswith("**") and not prompt.startswith("*"):
                        image_prompts.append(prompt)
        
        # Add any remaining prompt
        if current_prompt:
            image_prompts.append(current_prompt.strip())
        
        # Clean up prompts
        clean_prompts = []
        for prompt in image_prompts:
            # Remove any markdown formatting and clean up
            clean_prompt = prompt.replace("**", "").replace("*", "").strip()
            # Remove quotes
            clean_prompt = clean_prompt.strip('"').strip("'")
            if clean_prompt and len(clean_prompt) > 10:  # Ensure meaningful length
                clean_prompts.append(clean_prompt)
        
        # Limit to 5 prompts
        clean_prompts = clean_prompts[:5]
        
        return ["Create a high quality tattoo design based on the following details: " + prompt for prompt in clean_prompts]



    def run(self):
        """Main execution flow"""
        print("ğŸ¨ AI History Tattoo Generator")
        print("=" * 50)
        
        # Step 1: Check Ollama connection
        if not self.check_ollama_connection():
            return
        
        # Step 2: Load browsing history
        summary = self.load_history_summary()
        if not summary:
            return
        
        # Step 3: Generate tattoo prompts
        response = self.generate_tattoo_prompts(summary)
        if not response:
            return
        print(response, "((((())))))))))")
        # Step 4: Extract prompts and track keywords
        print("\nğŸ“ Extracting prompts for image generation...")
        image_prompts = self.extract_direct_prompts(response, summary)

        print(f"âœ… Extracted {len(image_prompts)} image prompts")
        print("\nğŸ“‹ Direct Prompts for Image Generation:")
        
        # Display prompts
        for i, prompt in enumerate(image_prompts, 1):
            print(f"\n{i}. {prompt}")
            print("-" * 80)
        
        # Save prompts
        self.save_prompts(response, image_prompts, summary)
        
        # Step 5: Generate images
        print("\nğŸ–¼ï¸  Generating images for tattoo ideas...")
        print("=" * 50)
        
        for i, prompt in enumerate(image_prompts, 1):
            print(f"\n--- Generating Tattoo {i}/{len(image_prompts)} ---")
            print(f"Prompt: {prompt}")
            
            success = self.generate_single_image(prompt, i)
            if success:
                print(f"âœ… Tattoo {i} generated successfully!")
            else:
                print(f"âŒ Failed to generate tattoo {i}")
            print("-" * 50)
        
        print("\nğŸ‰ Tattoo generation complete!")
        print("=" * 50)
        
        # List generated files
        import glob
        png_files = glob.glob("tattoo_*.png")
        if png_files:
            print(f"âœ… Generated {len(png_files)} images:")
            for file in sorted(png_files):
                print(f"   - {file}")
            print("\nCheck the generated PNG files in your current directory.")
        else:
            print("âŒ No images were generated.")

if __name__ == "__main__":
    generator = TattooGenerator()
    generator.run() 